{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name:李信儒(Hsin-Ju Li)\n",
    "\n",
    "Student ID:110033630\n",
    "\n",
    "GitHub ID:popo6699325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: do the **take home** exercises in the [DM2021-Lab1-master Repo](https://github.com/fhcalderon87/DM2021-Lab1-master). You may need to copy some cells from the Lab notebook to this notebook. __This part is worth 20% of your grade.__\n",
    "\n",
    "\n",
    "2. Second: follow the same process from the [DM2021-Lab1-master Repo](https://github.com/fhcalderon87/DM2021-Lab1-master) on **the new dataset**. You don't need to explain all details as we did (some **minimal comments** explaining your code are useful though).  __This part is worth 30% of your grade.__\n",
    "    - Download the [the new dataset](https://archive.ics.uci.edu/ml/datasets/Sentiment+Labelled+Sentences#). The dataset contains a `sentence` and `score` label. Read the specificiations of the dataset for details. \n",
    "    - You are allowed to use and modify the `helper` functions in the folder of the first lab session (notice they may need modification) or create your own.\n",
    "\n",
    "\n",
    "3. Third: please attempt the following tasks on **the new dataset**. __This part is worth 30% of your grade.__\n",
    "    - Generate meaningful **new data visualizations**. Refer to online resources and the Data Mining textbook for inspiration and ideas. \n",
    "    - Generate **TF-IDF features** from the tokens of each text. This will generating a document matrix, however, the weights will be computed differently (using the TF-IDF value of each word per document as opposed to the word frequency). Refer to this Sciki-learn [guide](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) .\n",
    "    - Implement a simple **Naive Bayes classifier** that automatically classifies the records into their categories. Use both the TF-IDF features and word frequency features to build two seperate classifiers. Comment on the differences.  Refer to this [article](https://hub.packtpub.com/implementing-3-naive-bayes-classifiers-in-scikit-learn/).\n",
    "\n",
    "\n",
    "4. Fourth: In the lab, we applied each step really quickly just to illustrate how to work with your dataset. There are somethings that are not ideal or the most efficient/meaningful. Each dataset can be handled differently as well. What are those inefficent parts you noticed? How can you improve the Data preprocessing for these specific datasets? __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "5. Fifth: It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**. __This part is worth 10% of your grade.__\n",
    "\n",
    "\n",
    "You can submit your homework following these guidelines: [Git Intro & How to hand your homework](https://github.com/fhcalderon87/DM2021-Lab1-master/blob/main/Git%20Intro%20%26%20How%20to%20hand%20your%20homework.ipynb). Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 4th 11:59 pm, Thursday)__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Begin Assignment Here\n",
    "#get amazon data\n",
    "amazon = []\n",
    "tmp = 'initial'\n",
    "with open('sentiment labelled sentences\\\\amazon_cells_labelled.txt','r') as fh:\n",
    "    while tmp:\n",
    "        tmp = fh.readline()\n",
    "        tmp=tmp.strip('\\n')\n",
    "        if tmp != '':\n",
    "            amazon.append(tmp)\n",
    "# get imdb data\n",
    "imdb = []\n",
    "tmp = 'initial'\n",
    "with open('sentiment labelled sentences\\\\imdb_labelled.txt','r',encoding=\"utf-8\") as fh:\n",
    "    while tmp:\n",
    "        tmp = fh.readline()\n",
    "        tmp=tmp.strip('\\n')\n",
    "        if tmp != '':\n",
    "            imdb.append(tmp)\n",
    "#get yelp data\n",
    "yelp = []\n",
    "tmp = 'initial'\n",
    "with open('sentiment labelled sentences\\\\yelp_labelled.txt','r') as fh:\n",
    "    while tmp:\n",
    "        tmp = fh.readline()\n",
    "        tmp=tmp.strip('\\n')\n",
    "        if tmp != '':\n",
    "            yelp.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_data = []\n",
    "All_label = []\n",
    "All_category_name = []\n",
    "All_category = []\n",
    "\n",
    "for information in amazon:\n",
    "    tmp = information.split('\\t')\n",
    "    All_data.append(tmp[0])\n",
    "    All_label.append(int(tmp[1]))\n",
    "    #All_category_name.append('amazon')\n",
    "    All_category.append(0)\n",
    "    \n",
    "for information in imdb:\n",
    "    tmp = information.split('\\t')\n",
    "    All_data.append(tmp[0])\n",
    "    All_label.append(int(tmp[1]))  \n",
    "    #All_category_name.append('imdb')\n",
    "    All_category.append(1)\n",
    "    \n",
    "for information in yelp:\n",
    "    tmp = information.split('\\t')\n",
    "    All_data.append(tmp[0])\n",
    "    All_label.append(int(tmp[1]))\n",
    "    #All_category_name.append('yelp')\n",
    "    All_category.append(2)\n",
    "\n",
    "All = []\n",
    "All.append(All_data)\n",
    "All.append(All_label)\n",
    "#All.append(All_category_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment_label\n",
       "0     So there is no way for me to plug it in here i...               0\n",
       "1                           Good case, Excellent value.               1\n",
       "2                                Great for the jawbone.               1\n",
       "3     Tied to charger for conversations lasting more...               0\n",
       "4                                     The mic is great.               1\n",
       "...                                                 ...             ...\n",
       "2995  I think food should have flavor and texture an...               0\n",
       "2996                           Appetite instantly gone.               0\n",
       "2997  Overall I was not impressed and would not go b...               0\n",
       "2998  The whole experience was underwhelming, and I ...               0\n",
       "2999  Then, as if I hadn't wasted enough of my life ...               0\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df_All = pd.DataFrame(np.array(All).T, columns = ['sentence', 'sentiment_label'])\n",
    "df_All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>If you have several dozen or several hundred c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>If you are Razr owner...you must have this!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Needless to say, I wasted my money.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What a waste of money and time!.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment_label\n",
       "0  So there is no way for me to plug it in here i...               0\n",
       "1                        Good case, Excellent value.               1\n",
       "2                             Great for the jawbone.               1\n",
       "3  Tied to charger for conversations lasting more...               0\n",
       "4                                  The mic is great.               1\n",
       "5  I have to jiggle the plug to get it to line up...               0\n",
       "6  If you have several dozen or several hundred c...               0\n",
       "7        If you are Razr owner...you must have this!               1\n",
       "8                Needless to say, I wasted my money.               0\n",
       "9                   What a waste of money and time!.               0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df_All))\n",
    "df_All[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So there is no way for me to plug it in here in the US unless I go by a converter.\n",
      "Good case, Excellent value.\n",
      "Great for the jawbone.\n",
      "Tied to charger for conversations lasting more than 45 minutes.MAJOR PROBLEMS!!\n",
      "The mic is great.\n"
     ]
    }
   ],
   "source": [
    "for t in df_All['sentence'][:5]:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>And those baby owls were adorable.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>The movie showed a lot of Florida at it's best...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>The Songs Were The Best And The Muppets Were S...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>It Was So Cool.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>This is a very \"right on case\" movie that deli...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1015</th>\n",
       "      <td>It had some average acting from the main perso...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>This review is long overdue, since I consider ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>I'll put this gem up against any movie in term...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>It's practically perfect in all of them  a tr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>\" The structure of this film is easily the mos...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment_label  \\\n",
       "1010               And those baby owls were adorable.                 1   \n",
       "1011  The movie showed a lot of Florida at it's best...               1   \n",
       "1012  The Songs Were The Best And The Muppets Were S...               1   \n",
       "1013                                  It Was So Cool.                 1   \n",
       "1014  This is a very \"right on case\" movie that deli...               1   \n",
       "1015  It had some average acting from the main perso...               0   \n",
       "1016  This review is long overdue, since I consider ...               1   \n",
       "1017  I'll put this gem up against any movie in term...               1   \n",
       "1018  It's practically perfect in all of them  a tr...               1   \n",
       "1019  \" The structure of this film is easily the mos...               1   \n",
       "\n",
       "      category category_name  \n",
       "1010         1          imdb  \n",
       "1011         1          imdb  \n",
       "1012         1          imdb  \n",
       "1013         1          imdb  \n",
       "1014         1          imdb  \n",
       "1015         1          imdb  \n",
       "1016         1          imdb  \n",
       "1017         1          imdb  \n",
       "1018         1          imdb  \n",
       "1019         1          imdb  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All['category']  = All_category\n",
    "df_All['category_name']=df_All.category.apply(lambda x:'amazon' if x == 0 else ('imdb' if x==1 else 'yelp'))\n",
    "df_All[1010:1020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2990</th>\n",
       "      <td>The refried beans that came with my meal were ...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2991</th>\n",
       "      <td>Spend your money and time some place else.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2992</th>\n",
       "      <td>A lady at the table next to us found a live gr...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2993</th>\n",
       "      <td>the presentation of the food was awful.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>I can't tell you how disappointed I was.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence category_name\n",
       "2990  The refried beans that came with my meal were ...          yelp\n",
       "2991         Spend your money and time some place else.          yelp\n",
       "2992  A lady at the table next to us found a live gr...          yelp\n",
       "2993            the presentation of the food was awful.          yelp\n",
       "2994           I can't tell you how disappointed I was.          yelp\n",
       "2995  I think food should have flavor and texture an...          yelp\n",
       "2996                           Appetite instantly gone.          yelp\n",
       "2997  Overall I was not impressed and would not go b...          yelp\n",
       "2998  The whole experience was underwhelming, and I ...          yelp\n",
       "2999  Then, as if I hadn't wasted enough of my life ...          yelp"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All[-10:][['sentence','category_name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And the sound quality is great.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I went on Motorola's website and followed all ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>This is a simple little phone to use, but the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>It has a great camera thats 2MP, and the pics ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             sentence sentiment_label  \\\n",
       "0   So there is no way for me to plug it in here i...               0   \n",
       "10                    And the sound quality is great.               1   \n",
       "20  I went on Motorola's website and followed all ...               0   \n",
       "30  This is a simple little phone to use, but the ...               0   \n",
       "40  It has a great camera thats 2MP, and the pics ...               1   \n",
       "\n",
       "    category  \n",
       "0          0  \n",
       "10         0  \n",
       "20         0  \n",
       "30         0  \n",
       "40         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All.iloc[::10,0:3][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "200     0\n",
       "400     0\n",
       "600     0\n",
       "800     0\n",
       "1000    1\n",
       "1200    1\n",
       "1400    1\n",
       "1600    1\n",
       "1800    1\n",
       "2000    2\n",
       "2200    2\n",
       "2400    2\n",
       "2600    2\n",
       "2800    2\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All.loc[::200,'category'][0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>Now I am getting angry and I want my damn pho.</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>Honeslty it didn't taste THAT fresh.)</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>The potatoes were like rubber and you could te...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>The fries were great too.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>A great touch.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment_label  \\\n",
       "2000                           Wow... Loved this place.               1   \n",
       "2001                                 Crust is not good.               0   \n",
       "2002          Not tasty and the texture was just nasty.               0   \n",
       "2003  Stopped by during the late May bank holiday of...               1   \n",
       "2004  The selection on the menu was great and so wer...               1   \n",
       "2005     Now I am getting angry and I want my damn pho.               0   \n",
       "2006              Honeslty it didn't taste THAT fresh.)               0   \n",
       "2007  The potatoes were like rubber and you could te...               0   \n",
       "2008                          The fries were great too.               1   \n",
       "2009                                     A great touch.               1   \n",
       "\n",
       "      category category_name  \n",
       "2000         2          yelp  \n",
       "2001         2          yelp  \n",
       "2002         2          yelp  \n",
       "2003         2          yelp  \n",
       "2004         2          yelp  \n",
       "2005         2          yelp  \n",
       "2006         2          yelp  \n",
       "2007         2          yelp  \n",
       "2008         2          yelp  \n",
       "2009         2          yelp  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All.loc[lambda t: t['category'] > 1,:][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>It is so small and you don't even realize that...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Worked perfectly!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>Sounds good reasonably priced and effective, I...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>Great case and price!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>Works well.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>Gets a signal when other Verizon phones won't.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>I was very impressed with the price of the cases.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1099</th>\n",
       "      <td>If you are looking for a movie with a terrific...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1304</th>\n",
       "      <td>his performance, as awarded, was stunning.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1414</th>\n",
       "      <td>I would have casted her in that role after rea...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>I saw this film over Christmas, and what a gre...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>Tom Wilkinson's character is a man who is not ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1831</th>\n",
       "      <td>See both films if you can.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>Enough can not be said of the remarkable anima...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>Best breakfast buffet!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>Waitress was good though!</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "      <td>This place is like Chipotle, but BETTER.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2468</th>\n",
       "      <td>Love the margaritas, too!</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>The waitress was friendly and happy to accomod...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment_label  \\\n",
       "1                           Good case, Excellent value.               1   \n",
       "130   It is so small and you don't even realize that...               1   \n",
       "271                                   Worked perfectly!               1   \n",
       "398   Sounds good reasonably priced and effective, I...               1   \n",
       "534                               Great case and price!               1   \n",
       "689                                         Works well.               1   \n",
       "817      Gets a signal when other Verizon phones won't.               1   \n",
       "961   I was very impressed with the price of the cases.               1   \n",
       "1099  If you are looking for a movie with a terrific...               1   \n",
       "1304       his performance, as awarded, was stunning.                 1   \n",
       "1414  I would have casted her in that role after rea...               1   \n",
       "1627  I saw this film over Christmas, and what a gre...               1   \n",
       "1743  Tom Wilkinson's character is a man who is not ...               1   \n",
       "1831                       See both films if you can.                 1   \n",
       "1970  Enough can not be said of the remarkable anima...               1   \n",
       "2093                           Best breakfast buffet!!!               1   \n",
       "2215                          Waitress was good though!               1   \n",
       "2346           This place is like Chipotle, but BETTER.               1   \n",
       "2468                          Love the margaritas, too!               1   \n",
       "2591  The waitress was friendly and happy to accomod...               1   \n",
       "\n",
       "      category category_name  \n",
       "1            0        amazon  \n",
       "130          0        amazon  \n",
       "271          0        amazon  \n",
       "398          0        amazon  \n",
       "534          0        amazon  \n",
       "689          0        amazon  \n",
       "817          0        amazon  \n",
       "961          0        amazon  \n",
       "1099         1          imdb  \n",
       "1304         1          imdb  \n",
       "1414         1          imdb  \n",
       "1627         1          imdb  \n",
       "1743         1          imdb  \n",
       "1831         1          imdb  \n",
       "1970         1          imdb  \n",
       "2093         2          yelp  \n",
       "2215         2          yelp  \n",
       "2346         2          yelp  \n",
       "2468         2          yelp  \n",
       "2591         2          yelp  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All.loc[lambda t: t.sentiment_label == '1'].iloc[::70,:][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Data Mining using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence  sentiment_label  category  category_name\n",
       "0        False            False     False          False\n",
       "1        False            False     False          False\n",
       "2        False            False     False          False\n",
       "3        False            False     False          False\n",
       "4        False            False     False          False\n",
       "...        ...              ...       ...            ...\n",
       "2995     False            False     False          False\n",
       "2996     False            False     False          False\n",
       "2997     False            False     False          False\n",
       "2998     False            False     False          False\n",
       "2999     False            False     False          False\n",
       "\n",
       "[3000 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence                     sentiment_label  \\\n",
       "0  The amoung of missing records is:   The amoung of missing records is:    \n",
       "1                                   0                                   0   \n",
       "\n",
       "                             category                       category_name  \n",
       "0  The amoung of missing records is:   The amoung of missing records is:   \n",
       "1                                   0                                   0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import helpers.data_mining_helpers as dmh\n",
    "df_All.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (The amoung of missing records is: , 0)\n",
       "1       (The amoung of missing records is: , 0)\n",
       "2       (The amoung of missing records is: , 0)\n",
       "3       (The amoung of missing records is: , 0)\n",
       "4       (The amoung of missing records is: , 0)\n",
       "                         ...                   \n",
       "2995    (The amoung of missing records is: , 0)\n",
       "2996    (The amoung of missing records is: , 0)\n",
       "2997    (The amoung of missing records is: , 0)\n",
       "2998    (The amoung of missing records is: , 0)\n",
       "2999    (The amoung of missing records is: , 0)\n",
       "Length: 3000, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All.isnull().apply(lambda x: dmh.check_missing_values(x), axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    dummy_record\n",
       "category               1\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_series = pd.Series([\"dummy_record\", 1], index=[\"sentence\", \"category\"])\n",
    "dummy_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence                     sentiment_label  \\\n",
       "0  The amoung of missing records is:   The amoung of missing records is:    \n",
       "1                                   0                                   1   \n",
       "\n",
       "                             category                       category_name  \n",
       "0  The amoung of missing records is:   The amoung of missing records is:   \n",
       "1                                   0                                   1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_with_series =df_All.append(dummy_series, ignore_index=True)\n",
    "print(len(result_with_series))\n",
    "result_with_series.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence                     sentiment_label  \\\n",
       "0  The amoung of missing records is:   The amoung of missing records is:    \n",
       "1                                   0                                   1   \n",
       "\n",
       "                             category                       category_name  \n",
       "0  The amoung of missing records is:   The amoung of missing records is:   \n",
       "1                                   0                                   1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_dict = [{'sentence': 'dummy_record',\n",
    "               'category': '1'\n",
    "              }]\n",
    "df_All_dummy = df_All.append(dummy_dict, ignore_index=True)\n",
    "print(len(df_All_dummy))\n",
    "df_All_dummy.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "      <td>The amoung of missing records is:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             sentence                     sentiment_label  \\\n",
       "0  The amoung of missing records is:   The amoung of missing records is:    \n",
       "1                                   0                                   0   \n",
       "\n",
       "                             category                       category_name  \n",
       "0  The amoung of missing records is:   The amoung of missing records is:   \n",
       "1                                   0                                   0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All_dummy.dropna(inplace=True)   #remove the raw of missing value\n",
    "df_All_dummy.isnull().apply(lambda x: dmh.check_missing_values(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(df_All_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Dealing with Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "        ...  \n",
       "2995    False\n",
       "2996    False\n",
       "2997    False\n",
       "2998    False\n",
       "2999    False\n",
       "Length: 3000, dtype: bool"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_duplicate = df_All[:]\n",
    "no_duplicate.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(no_duplicate.duplicated('sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "2983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-639f716a5ef5>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_duplicate.drop_duplicates(keep='first', inplace=True)  #remove duplicate but keep 1 element\n"
     ]
    }
   ],
   "source": [
    "print(len(no_duplicate))\n",
    "no_duplicate.drop_duplicates(keep='first', inplace=True)  #remove duplicate but keep 1 element\n",
    "print(len(no_duplicate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>category</th>\n",
       "      <th>category_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>The scenes are often funny and occasionally to...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>This device is great in several situations:1.)</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2137</th>\n",
       "      <td>This is one of the best bars with food in Vegas.</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>great...no problems at all!.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence sentiment_label  \\\n",
       "1096  The scenes are often funny and occasionally to...               1   \n",
       "69       This device is great in several situations:1.)               1   \n",
       "2137   This is one of the best bars with food in Vegas.               1   \n",
       "508                        great...no problems at all!.               1   \n",
       "\n",
       "      category category_name  \n",
       "1096         1          imdb  \n",
       "69           0        amazon  \n",
       "2137         2          yelp  \n",
       "508          0        amazon  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All_sample = df_All.sample(n=1000) #random state\n",
    "print(len(df_All_sample))\n",
    "df_All_sample[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp      1000\n",
      "amazon    1000\n",
      "imdb      1000\n",
      "Name: category_name, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Category distribution'}>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(df_All.category_name.value_counts())\n",
    "df_All.category_name.value_counts().plot(kind = 'bar',\n",
    "                                        title = 'Category distribution',\n",
    "                                        ylim = [0, 1100],        \n",
    "                                        rot = 0, fontsize = 11, figsize = (8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon    354\n",
      "yelp      328\n",
      "imdb      318\n",
      "Name: category_name, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Category distribution'}>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "upper_bound = max(df_All_sample.category_name.value_counts()) +10\n",
    "print(df_All_sample.category_name.value_counts())\n",
    "\n",
    "# plot barchart for X_sample\n",
    "df_All_sample.category_name.value_counts().plot(kind = 'bar',\n",
    "                                               title = 'Category distribution',\n",
    "                                               ylim = [0, upper_bound], \n",
    "                                               rot = 0, fontsize = 12, figsize = (8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yelp      1000\n",
      "amazon    1000\n",
      "imdb      1000\n",
      "Name: category_name, dtype: int64\n",
      "amazon    354\n",
      "yelp      328\n",
      "imdb      318\n",
      "Name: category_name, dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n",
      "           X  X_sample\n",
      "yelp    1000       328\n",
      "amazon  1000       354\n",
      "imdb    1000       318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Category_name distribution'}>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_X = df_All.category_name.value_counts()\n",
    "Y_X_sample = df_All_sample.category_name.value_counts()\n",
    "\n",
    "print(Y_X)\n",
    "print(Y_X_sample)\n",
    "print(type(Y_X))\n",
    "df = pd.concat([Y_X,Y_X_sample], axis=1)\n",
    "df.columns = ['X', 'X_sample']\n",
    "print(df)\n",
    "df.plot(kind = 'bar',\n",
    "        title = 'Category_name distribution',\n",
    "        rot = 0, fontsize = 12, figsize = (8,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Feature Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [So, there, is, no, way, for, me, to, plug, it...\n",
       "1                 [Good, case, ,, Excellent, value, .]\n",
       "2                        [Great, for, the, jawbone, .]\n",
       "3    [Tied, to, charger, for, conversations, lastin...\n",
       "Name: unigrams, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All['unigrams'] = df_All['sentence'].apply(lambda x: dmh.tokenize_text(x))\n",
    "df_All[0:4]['unigrams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['So',\n",
       "  'there',\n",
       "  'is',\n",
       "  'no',\n",
       "  'way',\n",
       "  'for',\n",
       "  'me',\n",
       "  'to',\n",
       "  'plug',\n",
       "  'it',\n",
       "  'in',\n",
       "  'here',\n",
       "  'in',\n",
       "  'the',\n",
       "  'US',\n",
       "  'unless',\n",
       "  'I',\n",
       "  'go',\n",
       "  'by',\n",
       "  'a',\n",
       "  'converter',\n",
       "  '.']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(df_All[0:1]['unigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Feature subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['so',\n",
       " 'there',\n",
       " 'is',\n",
       " 'no',\n",
       " 'way',\n",
       " 'for',\n",
       " 'me',\n",
       " 'to',\n",
       " 'plug',\n",
       " 'it',\n",
       " 'in',\n",
       " 'here',\n",
       " 'in',\n",
       " 'the',\n",
       " 'us',\n",
       " 'unless',\n",
       " 'go',\n",
       " 'by',\n",
       " 'converter']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "df_All_counts = count_vect.fit_transform(df_All.sentence)\n",
    "\n",
    "analyze = count_vect.build_analyzer()\n",
    "analyze(\" \".join(list(df_All[:1].sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 5155)\n",
      "['00', '10', '100', '11', '12', '13', '15', '15g', '15pm', '17']\n"
     ]
    }
   ],
   "source": [
    "print(df_All_counts.shape)\n",
    "print(count_vect.get_feature_names()[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_All_counts[0:5,0:100].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 46 record :45\n"
     ]
    }
   ],
   "source": [
    "array = df_All_counts[3:4].toarray()[0]\n",
    "count = 0\n",
    "first = 0\n",
    "for i in range(len(array)):\n",
    "    if array[i] == 1:\n",
    "        count+=1\n",
    "        if count == 1:\n",
    "            first = i\n",
    "            break\n",
    "print(\"The \"+str(first+1)+\" record :\",end='')\n",
    "print(count_vect.get_feature_names()[first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.transform(['Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 0, 1, 0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.transform(['00 100 zombie Something completely new.']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term_00',\n",
       " 'term_10',\n",
       " 'term_100',\n",
       " 'term_11',\n",
       " 'term_12',\n",
       " 'term_13',\n",
       " 'term_15',\n",
       " 'term_15g',\n",
       " 'term_15pm',\n",
       " 'term_17',\n",
       " 'term_18',\n",
       " 'term_18th',\n",
       " 'term_1928',\n",
       " 'term_1947',\n",
       " 'term_1948',\n",
       " 'term_1949',\n",
       " 'term_1971',\n",
       " 'term_1973',\n",
       " 'term_1979',\n",
       " 'term_1980',\n",
       " 'term_1986',\n",
       " 'term_1995',\n",
       " 'term_1998',\n",
       " 'term_20',\n",
       " 'term_2000',\n",
       " 'term_2005',\n",
       " 'term_2006',\n",
       " 'term_2007',\n",
       " 'term_20th',\n",
       " 'term_2160',\n",
       " 'term_23',\n",
       " 'term_24',\n",
       " 'term_25',\n",
       " 'term_2mp',\n",
       " 'term_30',\n",
       " 'term_30s',\n",
       " 'term_325',\n",
       " 'term_35',\n",
       " 'term_350',\n",
       " 'term_375',\n",
       " 'term_3o',\n",
       " 'term_40',\n",
       " 'term_40min',\n",
       " 'term_42',\n",
       " 'term_44',\n",
       " 'term_45',\n",
       " 'term_4s',\n",
       " 'term_4ths',\n",
       " 'term_50',\n",
       " 'term_5020']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_x = [\"term_\"+str(i) for i in count_vect.get_feature_names()[0:50]]\n",
    "plot_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doc_0',\n",
       " 'doc_1',\n",
       " 'doc_2',\n",
       " 'doc_3',\n",
       " 'doc_4',\n",
       " 'doc_5',\n",
       " 'doc_6',\n",
       " 'doc_7',\n",
       " 'doc_8',\n",
       " 'doc_9',\n",
       " 'doc_10',\n",
       " 'doc_11',\n",
       " 'doc_12',\n",
       " 'doc_13',\n",
       " 'doc_14',\n",
       " 'doc_15',\n",
       " 'doc_16',\n",
       " 'doc_17',\n",
       " 'doc_18',\n",
       " 'doc_19',\n",
       " 'doc_20',\n",
       " 'doc_21',\n",
       " 'doc_22',\n",
       " 'doc_23',\n",
       " 'doc_24',\n",
       " 'doc_25',\n",
       " 'doc_26',\n",
       " 'doc_27',\n",
       " 'doc_28',\n",
       " 'doc_29',\n",
       " 'doc_30',\n",
       " 'doc_31',\n",
       " 'doc_32',\n",
       " 'doc_33',\n",
       " 'doc_34',\n",
       " 'doc_35',\n",
       " 'doc_36',\n",
       " 'doc_37',\n",
       " 'doc_38',\n",
       " 'doc_39',\n",
       " 'doc_40',\n",
       " 'doc_41',\n",
       " 'doc_42',\n",
       " 'doc_43',\n",
       " 'doc_44',\n",
       " 'doc_45',\n",
       " 'doc_46',\n",
       " 'doc_47',\n",
       " 'doc_48',\n",
       " 'doc_49']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_y = [\"doc_\"+ str(i) for i in list(df_All.index)[0:50]]\n",
    "plot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_z = df_All_counts[0:50, 0:50].toarray()\n",
    "plot_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df_todraw = pd.DataFrame(plot_z, columns = plot_x, index = plot_y)\n",
    "plt.subplots(figsize=(9, 7))\n",
    "ax = sns.heatmap(df_todraw,\n",
    "                 cmap=\"PuRd\",\n",
    "                 vmin=0, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 200\n",
    "plot_x2 = [\"term_\"+str(i) for i in count_vect.get_feature_names()[0:number]]\n",
    "plot_y2 = [\"doc_\"+ str(i) for i in list(df_All.index)[0:number]]\n",
    "plot_z2 = df_All_counts[0:number, 0:number].toarray()\n",
    "\n",
    "remove_index_raw = []\n",
    "remove_index_column = []\n",
    "for i in range(number):\n",
    "    if sum(plot_z2[i]) == 0:\n",
    "        remove_index_raw.append(i)\n",
    "    if sum(plot_z2[:,i]) == 0:\n",
    "        remove_index_column.append(i)\n",
    "new_plot_z2 = np.delete(plot_z2, remove_index_raw, axis = 0)\n",
    "new_plot_z2 = np.delete(new_plot_z2, remove_index_column, axis = 1)\n",
    "new_plot_y2 = np.delete(plot_y2, remove_index_raw)\n",
    "new_plot_x2 = np.delete(plot_x2, remove_index_column)\n",
    "\n",
    "df_todraw2 = pd.DataFrame(new_plot_z2, columns = new_plot_x2, index = new_plot_y2)\n",
    "plt.subplots(figsize=(9, 7))\n",
    "ax = sns.heatmap(df_todraw2,\n",
    "                 cmap=\"PuRd\",\n",
    "                 vmin=0, vmax=1, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "df_All_reduced = PCA(n_components = 2).fit_transform(df_All_counts.toarray())\n",
    "print(df_All_counts.shape)\n",
    "print(df_All_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D\n",
    "col = ['coral', 'blue', 'm']\n",
    "categories = ['amazon', 'imdb', 'yelp']\n",
    "# plot\n",
    "fig = plt.figure(figsize = (25,10))\n",
    "ax = fig.subplots()\n",
    "\n",
    "for c, category in zip(col, categories):\n",
    "    xs = df_All_reduced[df_All['category_name'] == category].T[0]\n",
    "    ys = df_All_reduced[df_All['category_name'] == category].T[1]\n",
    "   \n",
    "    ax.scatter(xs, ys, c = c, marker='o')\n",
    "\n",
    "ax.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax.set_xlabel('\\nX Label')\n",
    "ax.set_ylabel('\\nY Label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "df_All_reduced = PCA(n_components = 3).fit_transform(df_All_counts.toarray())\n",
    "col = ['coral', 'blue', 'm']\n",
    "# plot\n",
    "fig0 = plt.figure(0,figsize = (5,5))\n",
    "fig1 = plt.figure(1,figsize = (5,5))\n",
    "fig2 = plt.figure(2,figsize = (5,5))\n",
    "ax0 = Axes3D(fig0, elev = 30, azim = 0)\n",
    "ax1 = Axes3D(fig1, elev = 30, azim = 120)\n",
    "ax2 = Axes3D(fig2, elev = 30, azim = 240)\n",
    "\n",
    "for c, category in zip(col, categories):\n",
    "    xs = df_All_reduced[df_All['category_name'] == category].T[0]\n",
    "    ys = df_All_reduced[df_All['category_name'] == category].T[1]\n",
    "    zs = df_All_reduced[df_All['category_name'] == category].T[2]\n",
    "    \n",
    "    ax0.scatter(xs, ys, c = c, marker='o')\n",
    "    ax1.scatter(xs, ys, c = c, marker='o')\n",
    "    ax2.scatter(xs, ys, c = c, marker='o')\n",
    "\n",
    "ax0.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax1.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "ax2.grid(color='gray', linestyle=':', linewidth=2, alpha=0.2)\n",
    "\n",
    "ax0.set_xlabel('\\nX Label')\n",
    "ax1.set_xlabel('\\nX Label')\n",
    "ax2.set_xlabel('\\nX Label')\n",
    "\n",
    "ax0.set_ylabel('\\nY Label')\n",
    "ax1.set_ylabel('\\nY Label')\n",
    "ax2.set_ylabel('\\nY Label')\n",
    "\n",
    "ax0.set_zlabel('\\nZ Label')\n",
    "ax1.set_zlabel('\\nZ Label')\n",
    "ax2.set_zlabel('\\nZ Label')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Attribute Transformation / Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequencies = []\n",
    "for j in range(0,df_All_counts.shape[1]):\n",
    "    term_frequencies.append(sum(df_All_counts[:,j].toarray()))\n",
    "print(term_frequencies)\n",
    "print(len(term_frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_frequencies = np.asarray(df_All_counts.sum(axis=0))[0]\n",
    "print(term_frequencies)\n",
    "print(len(term_frequencies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(100, 10))\n",
    "g = sns.barplot(x=count_vect.get_feature_names()[:300], \n",
    "            y=term_frequencies[:300])\n",
    "g.set_xticklabels(count_vect.get_feature_names()[:300], rotation = 90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "term_frequencies2 = np.asarray(df_All_counts.sum(axis=0))[0]\n",
    "fig = px.scatter(x=count_vect.get_feature_names()[:300], y=term_frequencies2[:300])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "number = 5155\n",
    "term_frequencies3 = np.asarray(df_All_counts.sum(axis=0))[0]\n",
    "term_frequencies3 = term_frequencies3[:number]\n",
    "x_feature = count_vect.get_feature_names()[:number]\n",
    "x_feature = np.array(x_feature)\n",
    "\n",
    "remove_index = []\n",
    "\n",
    "for i in range(number):\n",
    "    if term_frequencies3[i] < 50:\n",
    "        remove_index.append(i)\n",
    "new_term_frequencies3 = np.delete(term_frequencies3, remove_index)\n",
    "new_x_feature = np.delete(x_feature, remove_index)\n",
    "\n",
    "print(new_term_frequencies3)\n",
    "print(new_x_feature)\n",
    "\n",
    "fig = px.scatter(x=new_x_feature, y=new_term_frequencies3)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "number = 200\n",
    "term_frequencies3 = np.asarray(df_All_counts.sum(axis=0))[0]\n",
    "term_frequencies3 = term_frequencies3[:number]\n",
    "x_feature = count_vect.get_feature_names()[:number]\n",
    "\n",
    "data = {'frequency':term_frequencies3,'feature':x_feature}\n",
    "df_data = pd.DataFrame(data=data)\n",
    "df_data_sort=df_data.sort_values(by=['frequency'],ascending=False)\n",
    "\n",
    "sort_frequncies=list(df_data_sort['frequency'])\n",
    "sort_feature=list(df_data_sort['feature'])\n",
    "\n",
    "fig = px.bar(x=sort_feature,y=sort_frequncies)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "term_frequencies_log = [math.log(i) for i in term_frequencies]\n",
    "\n",
    "plt.subplots(figsize=(100, 10))\n",
    "g = sns.barplot(x=count_vect.get_feature_names()[:300],\n",
    "                y=term_frequencies_log[:300])\n",
    "g.set_xticklabels(count_vect.get_feature_names()[:300], rotation = 90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.6 Discretization and Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, metrics, decomposition, pipeline, dummy\n",
    "mlb = preprocessing.LabelBinarizer()\n",
    "mlb.fit(df_All.category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_All['bin_category'] = mlb.transform(df_All['category']).tolist()\n",
    "df_All[::500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb.fit(df_All.category_name)\n",
    "print(mlb.classes_)\n",
    "df_All['bin_category_name'] = mlb.transform(df_All['category_name']).tolist()\n",
    "df_All[::500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_to_transform_1 = []\n",
    "random_record_1 = df_All.iloc[50]\n",
    "random_record_1 = random_record_1['sentence']\n",
    "document_to_transform_1.append(random_record_1)\n",
    "\n",
    "document_to_transform_2 = []\n",
    "random_record_2 = df_All.iloc[100]\n",
    "random_record_2 = random_record_2['sentence']\n",
    "document_to_transform_2.append(random_record_2)\n",
    "\n",
    "document_to_transform_3 = []\n",
    "random_record_3 = df_All.iloc[150]\n",
    "random_record_3 = random_record_3['sentence']\n",
    "document_to_transform_3.append(random_record_3)\n",
    "\n",
    "print(document_to_transform_1)\n",
    "print(document_to_transform_2)\n",
    "print(document_to_transform_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import binarize\n",
    "\n",
    "# Transform sentence with Vectorizers\n",
    "document_vector_count_1 = count_vect.transform(document_to_transform_1)\n",
    "document_vector_count_2 = count_vect.transform(document_to_transform_2)\n",
    "document_vector_count_3 = count_vect.transform(document_to_transform_3)\n",
    "\n",
    "# Binarize vecors to simplify: 0 for abscence, 1 for prescence\n",
    "document_vector_count_1_bin = binarize(document_vector_count_1)\n",
    "document_vector_count_2_bin = binarize(document_vector_count_2)\n",
    "document_vector_count_3_bin = binarize(document_vector_count_3)\n",
    "\n",
    "# print\n",
    "print(\"Let's take a look at the count vectors:\")\n",
    "print(document_vector_count_1.todense())\n",
    "print(document_vector_count_2.todense())\n",
    "print(document_vector_count_3.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate Cosine Similarity\n",
    "cos_sim_count_1_2 = cosine_similarity(document_vector_count_1, document_vector_count_2, dense_output=True)\n",
    "cos_sim_count_1_3 = cosine_similarity(document_vector_count_1, document_vector_count_3, dense_output=True)\n",
    "cos_sim_count_2_3 = cosine_similarity(document_vector_count_2, document_vector_count_3, dense_output=True)\n",
    "cos_sim_count_1_1 = cosine_similarity(document_vector_count_1, document_vector_count_1, dense_output=True)\n",
    "cos_sim_count_2_2 = cosine_similarity(document_vector_count_2, document_vector_count_2, dense_output=True)\n",
    "\n",
    "\n",
    "# Print \n",
    "print(\"Cosine Similarity using count bw 1 and 2: %(x)f\" %{\"x\":cos_sim_count_1_2})\n",
    "print(\"Cosine Similarity using count bw 1 and 3: %(x)f\" %{\"x\":cos_sim_count_1_3})\n",
    "print(\"Cosine Similarity using count bw 2 and 3: %(x)f\" %{\"x\":cos_sim_count_2_3})\n",
    "print(\"Cosine Similarity using count bw 1 and 1: %(x)f\" %{\"x\":cos_sim_count_1_1})\n",
    "print(\"Cosine Similarity using count bw 2 and 2: %(x)f\" %{\"x\":cos_sim_count_2_2})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Visulazition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "number = 5155\n",
    "term_frequencies3 = np.asarray(df_All_counts.sum(axis=0))[0]\n",
    "term_frequencies3 = term_frequencies3[:number]\n",
    "x_feature = count_vect.get_feature_names()[:number]\n",
    "x_feature = np.array(x_feature)\n",
    "\n",
    "remove_index = []\n",
    "\n",
    "for i in range(number):\n",
    "    if term_frequencies3[i] < 50:\n",
    "        remove_index.append(i)\n",
    "new_term_frequencies3 = np.delete(term_frequencies3, remove_index)\n",
    "new_x_feature = np.delete(x_feature, remove_index)\n",
    "\n",
    "print(new_term_frequencies3)\n",
    "print(new_x_feature)\n",
    "\n",
    "fig = px.scatter(x=new_x_feature, y=new_term_frequencies3,size = new_term_frequencies3)\n",
    "fig.show()\n",
    "# delete some word with low frequency.\n",
    "# use size to let us know the differences between each other.\n",
    "# the larger circle , the more important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tf_vectorizer.fit_transform(df_All.sentence)\n",
    "word_list = tf_vectorizer.get_feature_names()\n",
    "weight_list = tfidf.toarray()\n",
    "print(tfidf.shape)\n",
    "\n",
    "for i in range(len(weight_list)):\n",
    "    print(\"---- The weight of the \", i+1,\" sentence.----\")\n",
    "    for j in range(len(word_list)):\n",
    "        if weight_list[i][j] !=0:\n",
    "            print(word_list[j], weight_list[i][j])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(weight_list, columns=word_list)\n",
    "df_tfidf\n",
    "#TfidfVectorizer calculate frequency of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = pd.DataFrame(df_All_counts.toarray(), columns = count_vect.get_feature_names())\n",
    "df_count\n",
    "#CountVectorizer determine if the word appear in this sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_All_shuffle = df_All.sample(frac=1)  #suffle\n",
    "size = 2000\n",
    "train_data = df_All_shuffle.sentence[0:size]\n",
    "test_data = df_All_shuffle.sentence[size:]\n",
    "train_label = df_All_shuffle.category[0:size]\n",
    "test_label = df_All_shuffle.category[size:]\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(train_data, train_label)\n",
    "labels = model.predict(test_data)\n",
    "print(test_label)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "mat = confusion_matrix(test_label, labels)\n",
    "\n",
    "sns.heatmap(mat.T, square = True, annot = True, fmt = 'd', cbar = False,\n",
    "            xticklabels = categories, yticklabels = categories)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label');\n",
    "#predict category of sentence => use confusion matrix to show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_All_shuffle = df_All.sample(frac=1)  #suffle\n",
    "size = 2000\n",
    "train_data = df_All_shuffle.sentence[0:size]\n",
    "test_data = df_All_shuffle.sentence[size:]\n",
    "train_label = df_All_shuffle.sentiment_label[0:size]\n",
    "test_label = df_All_shuffle.sentiment_label[size:]\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer()\n",
    "train_data_tf = tf_vectorizer.fit_transform(train_data)\n",
    "test_data_tf = tf_vectorizer.transform(test_data)\n",
    "\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(train_data_tf, train_label)\n",
    "\n",
    "y_pred = naive_bayes_classifier.predict(test_data_tf)\n",
    "score = metrics.accuracy_score(test_label, y_pred)\n",
    "print(\"accuracy: %0.1f\" %(score*100) + \"%\")\n",
    "#find test sentiment label=>calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_All_shuffle = df_All.sample(frac=1)  #suffle data\n",
    "size = 2000\n",
    "train_data = df_All_shuffle.sentence[0:size]\n",
    "test_data = df_All_shuffle.sentence[size:]\n",
    "train_label = df_All_shuffle.category_name[0:size]\n",
    "test_label = df_All_shuffle.category_name[size:]\n",
    "\n",
    "tf_vectorizer = TfidfVectorizer()\n",
    "train_data_tf = tf_vectorizer.fit_transform(train_data)\n",
    "test_data_tf = tf_vectorizer.transform(test_data)\n",
    "\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "naive_bayes_classifier.fit(train_data_tf, train_label)\n",
    "\n",
    "y_pred = naive_bayes_classifier.predict(test_data_tf)\n",
    "score = metrics.accuracy_score(test_label, y_pred)\n",
    "print(\"accuracy: %0.1f\" %(score*100) + \"%\")\n",
    "#find test category_name=>calculate accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Improve the efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In feature subset selection, the vectorizer is so big.\n",
    "Then, in every text vector is so many 0. Maybe it can leave some important information. If the frequency of the word is too low, we can remove it. Keep the more crucial words. Then the visualization can be more explicit.\n",
    "\n",
    "In aggregation part, sum data in every column spend long times.\n",
    "like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''term_frequencies = []\n",
    "for j in range(0,X_counts.shape[1]):\n",
    "    term_frequencies.append(sum(X_counts[:,j].toarray()))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it can use another way to calculate the total number like below. It save more time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#term_frequencies = np.asarray(X_counts.sum(axis=0))[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
